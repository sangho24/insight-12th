{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "U75TyrOJxNkF",
        "9IfeWkJQxTo_",
        "GpHrRHhq2IKU",
        "R66NCcg42M7F",
        "H8ku6-6221vg",
        "yNp19EQo3aa8"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sangho24/insight-12th/blob/main/EC5320_2024_2_Week9a_messy_tabular_data_v2_for_students_20200572.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EC5320 Week9a codes: Working with messy tabular data\n",
        "\n",
        "2024.10.29.<br>\n",
        "\n",
        "Author: Hyunjoo Yang (hyang@sogang.ac.kr)<br><br>\n",
        "\n",
        "This notebook uses Fastai and XGBoost to do classificaiton with messy tabular data.<br><br>\n",
        "\n",
        "Data source:<br>\n",
        "https://docs.fast.ai/tutorial.tabular.html <br>\n",
        "http://archive.ics.uci.edu/ml/datasets/Adult\n",
        "\n"
      ],
      "metadata": {
        "id": "-b47Z3BtkAE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 기말고사 project\n",
        "코랩 파일, 워드 파일\n",
        "\n",
        "1. 문제의식\n",
        "2. 뭘 할 거\n",
        "3. 사용하는 머신러닝 모델\n",
        "4. 데이터 전처리\n",
        "5. 결과\n",
        "6. 의미와 결론\n",
        "7.\n",
        "\n",
        "재미있는 아이디어, 어떤 데이터를 모았는지, motivation은 뭐였는지 -> 기술 측면과 아이디어!"
      ],
      "metadata": {
        "id": "5wEsy9bs9MKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 중간고사 내용  \n",
        "## part1)\n",
        "1.4 augmentation 과적합을 막기 위해 쓸 수 있다 or 방향을 고려해야 하는 데이터의 경우 augmentation을 진행하면 안 된다.\n",
        "1.5 epoch는 시간 제약에 따라 자유롭게 설정할 수 있음. But patience를 늘릴수록 global maximum 에 도달할 확률이 높음, 돌리기 전에는 알 수 없음.\n",
        "1.8 accuracy 정도에 따라 결정하면 되는데, domain마다 다름. 도박같은 경우 50.1만 넘어도 쓸만한 모델일 것.\n",
        "1.11 validation set의 accuracy가 떨어지는 부분이 있다면 overfitting sign\n",
        "\n",
        "## part2)\n",
        "주어진 data에 rotation이 많으면 XGBoost 모델 쓰기 어려움\n",
        "2.9 CNN, XGBoost 모두 사용, class별 확률을 평균을 낸다...?\n",
        "\n"
      ],
      "metadata": {
        "id": "EQfjHEwo-4GF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Prepare data"
      ],
      "metadata": {
        "id": "U75TyrOJxNkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fastai\n",
        "print(fastai.__version__)\n",
        "\n",
        "#from fastai.vision.all import *\n",
        "#from fastai.text.all import *\n",
        "#from fastai.collab import *\n",
        "from fastai.tabular.all import *\n",
        "\n",
        "from matplotlib.pyplot import imshow"
      ],
      "metadata": {
        "id": "9SCZ0zut_z7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" upload adult.csv \"\"\""
      ],
      "metadata": {
        "id": "BywU_6AJRq5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('adult.csv', low_memory=False)\n",
        "df.sample(10)"
      ],
      "metadata": {
        "id": "0-gK3DiDAkiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "RVx_sbV_CNVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check missing values\n",
        "\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "RC31BjKHyCFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Classification with tabular data (FASTAI version)"
      ],
      "metadata": {
        "id": "9IfeWkJQxTo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare fastai tabular data\n",
        "\n",
        "to = TabularPandas(df, procs=[Categorify, FillMissing, Normalize],\n",
        "                   cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race'],\n",
        "                   cont_names = ['age', 'education-num'],\n",
        "                   y_names='salary',\n",
        "                   y_block = CategoryBlock,\n",
        "                   splits=RandomSplitter(valid_pct=0.2)(range_of(df))\n",
        "                   )"
      ],
      "metadata": {
        "id": "qhz3xlPSR6qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(to.train), len(to.valid)"
      ],
      "metadata": {
        "id": "xGq96AjoB3ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to.show(3)"
      ],
      "metadata": {
        "id": "qUSffYXPCFtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to.items.head(3)"
      ],
      "metadata": {
        "id": "gpoDxkc8CJFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to.classes"
      ],
      "metadata": {
        "id": "LHyx7VFiCjBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check X variables (xs)\n",
        "to.xs.head()"
      ],
      "metadata": {
        "id": "sTXt6jeYBtGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check y variables (xs)\n",
        "to.ys.head()"
      ],
      "metadata": {
        "id": "nrQ0XbuxBuGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load tabular data to dataloader\n",
        "dls = to.dataloaders(bs=64)"
      ],
      "metadata": {
        "id": "xs2OA-QSCpOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# begin training\n",
        "\n",
        "beta = 2\n",
        "what_to_monitor = 'fbeta_score' # precision_score, recall_score, fbeta_score\n",
        "\n",
        "learn = tabular_learner(dls,\n",
        "                        metrics=[accuracy, Precision(), Recall(), FBeta(beta)]).to_fp16()\n",
        "\n",
        "# tabular_learner option: layers[500,250]\n",
        "\n",
        "learn.path = Path('./')\n",
        "\n",
        "learn.fit_one_cycle(20, cbs=[EarlyStoppingCallback(monitor=what_to_monitor, patience=5),\n",
        "                                       SaveModelCallback(monitor=what_to_monitor)])"
      ],
      "metadata": {
        "id": "koR0CC-_CyAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#learn.show_results()"
      ],
      "metadata": {
        "id": "FpL6zkmzC_2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "\n",
        "fastai_interp = ClassificationInterpretation.from_learner(learn)\n",
        "fastai_interp.plot_confusion_matrix()"
      ],
      "metadata": {
        "id": "ZjWQF_muYIJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix (normalized)\n",
        "\n",
        "fastai_interp.plot_confusion_matrix(normalize=True)"
      ],
      "metadata": {
        "id": "Wr5p832lYRF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict using an observation\n",
        "df.iloc[0]"
      ],
      "metadata": {
        "id": "EwVZXw5pWy-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row, clas, probs = learn.predict(df.iloc[0])"
      ],
      "metadata": {
        "id": "sTQAkMAMDDG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row.show()"
      ],
      "metadata": {
        "id": "3Olk1twtDIzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clas, probs"
      ],
      "metadata": {
        "id": "udhBpc56DKh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict using the whole df\n",
        "\n",
        "test_df = df.copy()\n",
        "test_df.drop(['salary'], axis=1, inplace=True)\n",
        "dl = learn.dls.test_dl(test_df)"
      ],
      "metadata": {
        "id": "Bc2GCeIXDNCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions\n",
        "\n",
        "learn.get_preds(dl=dl)"
      ],
      "metadata": {
        "id": "SrkM7bR-DUn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export preprocessed dfs\n",
        "\n",
        "X_train_fastai, y_train_fastai = to.train.xs, to.train.ys.values.ravel()\n",
        "X_valid_fastai, y_valid_fastai = to.valid.xs, to.valid.ys.values.ravel()"
      ],
      "metadata": {
        "id": "S9dHwCmqDWLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_fastai"
      ],
      "metadata": {
        "id": "51Nxn0ss1p7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Classificaiton with XGBoost"
      ],
      "metadata": {
        "id": "mCzmerftxgPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 install and import xgboost"
      ],
      "metadata": {
        "id": "GpHrRHhq2IKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import cv"
      ],
      "metadata": {
        "id": "l_yUp1MYEoxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set XGBoost regressor parameters\n",
        "\n",
        "my_random_seed = 128\n",
        "\n",
        "# use early stopping\n",
        "early_stop_rounds = 10\n",
        "\n",
        "xgb_classify_test = xgb.XGBClassifier(random_state=my_random_seed,\n",
        "                                 early_stopping_rounds=early_stop_rounds)"
      ],
      "metadata": {
        "id": "DaeDnoT1hxuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "## train\n",
        "\n",
        "xgb_classify_test.fit(X_train_fastai, y_train_fastai,\n",
        "            eval_set=[(X_valid_fastai, y_valid_fastai)])"
      ],
      "metadata": {
        "id": "iYquDKWiuiPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Prepare train, valid, test dataset"
      ],
      "metadata": {
        "id": "R66NCcg42M7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle data set\n",
        "my_seed = 42\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "df_shuffled = shuffle(df, random_state=my_seed)\n",
        "df_shuffled"
      ],
      "metadata": {
        "id": "0sf3_4Qpud5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set XX percent out of total sample (0.1, 0.3, 0.5, etc)\n",
        "# (np.fix: nearest integer towards zero)\n",
        "\n",
        "df_num_obs = df_shuffled.shape[0]\n",
        "\n",
        "\"\"\"\n",
        "num_train_samples = int(np.fix(df_num_obs * 0.6))\n",
        "num_val_samples = int(np.fix(df_num_obs * 0.2))\n",
        "num_test_samples = int(np.fix(df_num_obs * 0.2))\n",
        "\"\"\"\n",
        "\n",
        "# or set number\n",
        "\n",
        "num_train_samples = 20000\n",
        "num_val_samples = 3000\n",
        "num_test_samples = 3000\n",
        "\n",
        "print(num_train_samples, num_val_samples, num_test_samples)\n",
        "\n",
        "\n",
        "num_total_samples = num_train_samples + num_val_samples + num_test_samples\n",
        "num_train_val_samples = num_train_samples + num_val_samples\n"
      ],
      "metadata": {
        "id": "Dkk32wTvu0gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split df into train, validation and test sets\n",
        "\n",
        "df_train = df_shuffled[0:num_train_samples]\n",
        "\n",
        "df_valid = df_shuffled[num_train_samples:num_train_samples + num_val_samples]\n",
        "\n",
        "df_test = df_shuffled[num_train_samples + num_val_samples: num_total_samples]\n",
        "#df_test = df_shuffled[-num_test_samples:]\n",
        "\n",
        "print(df_train.shape[0], df_valid.shape[0], df_test.shape[0])"
      ],
      "metadata": {
        "id": "1WqbW5T4vWjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare ground truth data by convert '<50k' '>=50k' to 0 and 1\n",
        "\n",
        "print(df['salary'].value_counts())\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "y = le.fit_transform(df['salary'])\n",
        "\n",
        "print('')\n",
        "print('classes: {}'.format(le.classes_))\n",
        "print('')\n",
        "\n",
        "y"
      ],
      "metadata": {
        "id": "bPBSmjO4Xkjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['salary']"
      ],
      "metadata": {
        "id": "jDz3utnBaagb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split y into train, valid, test set\n",
        "\n",
        "y_train = y[0:num_train_samples]\n",
        "\n",
        "y_valid = y[num_train_samples:num_train_samples + num_val_samples]\n",
        "\n",
        "y_test = y[num_train_samples + num_val_samples: num_total_samples]\n",
        "#y_test = y[-num_test_samples:]\n",
        "\n",
        "print(y_train.shape[0], df_valid.shape[0], df_test.shape[0])\n",
        "\n",
        "y_train"
      ],
      "metadata": {
        "id": "m00rGm-1ardR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 preprocess variables"
      ],
      "metadata": {
        "id": "H8ku6-6221vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "CUqP_GdKvWmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "rC51aqGBvWpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to deal with missing values? <br>\n",
        "\n",
        "\n",
        "1.   Drop missing observations (df.dropna(subset=[\"education-num\"]))\n",
        "2.   Replace missing values with some stat (e.g., median or mean) using simple imputer\n",
        "\n"
      ],
      "metadata": {
        "id": "BEPd9DeFE2ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_vars = ['age', 'education-num']\n",
        "categorical_vars = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']"
      ],
      "metadata": {
        "id": "I3JXaSbD3Z9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the list of columns with missing values\n",
        "\n",
        "cols_with_missing = [col for col in df_train.columns\n",
        "                                 if df_train[col].isnull().any()]\n",
        "cols_with_missing"
      ],
      "metadata": {
        "id": "jXPOOrlOYDVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data preprocessing pipeline\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "numeric_vars = ['age', 'education-num']\n",
        "categorical_vars = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
        "\n",
        "numeric_pipeline = Pipeline([\n",
        "                             ('num imputer', SimpleImputer(strategy=\"median\", add_indicator=True)),\n",
        "                             ('std_scalder', StandardScaler())\n",
        "                             ])\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "                         ('cat imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
        "                         ('cat 1hot', OneHotEncoder(sparse_output=False, dtype=int))\n",
        "])\n",
        "# alternative: OrdinalEncoder\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "                                   (\"num\", numeric_pipeline, numeric_vars),\n",
        "                                   (\"cat\", cat_pipeline, categorical_vars)\n",
        "                                   ])"
      ],
      "metadata": {
        "id": "d8_PMFq1R1YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_prepared = pd.DataFrame(full_pipeline.fit_transform(df_train))\n",
        "df_train_prepared"
      ],
      "metadata": {
        "id": "JyzMDoIETGAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_valid_prepared = pd.DataFrame(full_pipeline.transform(df_valid))\n",
        "df_valid_prepared"
      ],
      "metadata": {
        "id": "LV7jOwo9a_8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 train using xgboost"
      ],
      "metadata": {
        "id": "yNp19EQo3aa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set XGBoost regressor parameters\n",
        "\n",
        "my_seed = 42\n",
        "\n",
        "early_stop_rounds = 20\n",
        "\n",
        "\n",
        "\"\"\" FOR REGRESSION\n",
        "params = {'objective':'reg:squarederror', 'eval_metric':'rmse',\n",
        "          'random_state':my_seed, 'nthread':-1, 'n_estimators':300\n",
        "        }\n",
        "xgb_reg = xgb.XGBRegressor(**params)\n",
        "\"\"\"\n",
        "# if gpu is used, add 'device':'cuda' below\n",
        "\n",
        "params = {'objective':'binary:logistic', 'eval_metric':'error',\n",
        "          'random_state':my_seed, 'nthread':-1, 'n_estimators':300,\n",
        "          'early_stopping_rounds':early_stop_rounds\n",
        "          }\n",
        "\n",
        "# for multiclass classification: 'objective':'reg:squarederror' ('eval_metric':'merror')\n",
        "# check: https://xgboost.readthedocs.io/en/stable/parameter.html\n",
        "\n",
        "xgb_classify = xgb.XGBClassifier(**params)\n",
        "\n",
        "#print(xgb_reg)"
      ],
      "metadata": {
        "id": "D2YMz47YEq0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# train\n",
        "\n",
        "xgb_classify.fit(df_train_prepared, y_train,\n",
        "            eval_set=[(df_valid_prepared, y_valid)], )"
      ],
      "metadata": {
        "id": "c5UuebLjErqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get validation set prediction results\n",
        "\n",
        "y_pred_xgb = xgb_classify.predict(df_valid_prepared)\n",
        "y_pred_xgb"
      ],
      "metadata": {
        "id": "_5LcCzIEFAV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get validation set prediction results\n",
        "\n",
        "y_pred_proba_xgb = xgb_classify.predict_proba(df_valid_prepared)\n",
        "y_pred_proba_xgb"
      ],
      "metadata": {
        "id": "h7_ElpXeFPak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix plot\n",
        "\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True):\n",
        "    \"\"\"\n",
        "    given a sklearn confusion matrix (cm), make a nice plot\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
        "    target_names: given classification classes such as [0, 1, 2]\n",
        "                  the class names, for example: ['high', 'medium', 'low']\n",
        "    title:        the text to display at the top of the matrix\n",
        "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
        "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "                  plt.get_cmap('jet') or plt.cm.Blues\n",
        "    normalize:    If False, plot the raw numbers\n",
        "                  If True, plot the proportions\n",
        "\n",
        "    Citiation\n",
        "    ---------\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    plt.figure(figsize=(12, 9))\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.3f}; misclass={:0.3f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aWhogvizX4U4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrics\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "conf_mx = confusion_matrix(y_valid, y_pred_xgb)"
      ],
      "metadata": {
        "id": "6ksXiodHfHYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot confusion matrix (raw)\n",
        "\n",
        "my_classes = [0,1]\n",
        "\n",
        "plot_confusion_matrix(conf_mx, my_classes, cmap=None, normalize=False)"
      ],
      "metadata": {
        "id": "kRclGVD-fQRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(conf_mx, my_classes, cmap='Reds', normalize=True)"
      ],
      "metadata": {
        "id": "HWca3h2ofSiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set scale pos weight for imbalanced classification problems\n",
        "# scale_pos_weight = total_negative_examples / total_positive_examples\n",
        "\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)\n",
        "\n",
        "my_scale_pos_weight = 15184 / 4816\n",
        "my_scale_pos_weight"
      ],
      "metadata": {
        "id": "qbV81mulfW4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params2 = {'objective':'binary:logistic', 'eval_metric':'error',\n",
        "           'random_state':my_seed, 'nthread':-1, 'n_estimators':300,\n",
        "           'early_stopping_rounds':early_stop_rounds,\n",
        "           'scale_pos_weight':my_scale_pos_weight\n",
        "        }\n",
        "\n",
        "# for multiclass classification: 'objective':'reg:squarederror' ('eval_metric':'merror')\n",
        "# check: https://xgboost.readthedocs.io/en/stable/parameter.html\n",
        "\n",
        "xgb_classify2 = xgb.XGBClassifier(**params2)"
      ],
      "metadata": {
        "id": "BoH8oyiVgVDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "early_stop_rounds = 50\n",
        "\n",
        "# use early stopping\n",
        "\n",
        "xgb_classify2.fit(df_train_prepared, y_train,\n",
        "            eval_set=[(df_valid_prepared, y_valid)])"
      ],
      "metadata": {
        "id": "ffNwjiXDhWQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get validation set prediction results\n",
        "\n",
        "y_pred_xgb2 = xgb_classify2.predict(df_valid_prepared)\n",
        "y_pred_xgb2"
      ],
      "metadata": {
        "id": "7gdTvtvqhaUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mx2 = confusion_matrix(y_valid, y_pred_xgb2)"
      ],
      "metadata": {
        "id": "NyHzSf9BwvwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(conf_mx2, my_classes, cmap='Reds', normalize=True)"
      ],
      "metadata": {
        "id": "CheQQ2t2wzEl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}